{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_entity_id</th>\n",
       "      <th>relation_id</th>\n",
       "      <th>object_entity_id</th>\n",
       "      <th>temporal_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3573</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_entity_id  relation_id  object_entity_id  temporal_id\n",
       "0                  0            0             10203            0\n",
       "1                  1            1               244            0\n",
       "2                  1            1             16606            0\n",
       "3                  1            1             16607            0\n",
       "4                  1            1              3573            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'norm_IndovestDKG_encoded_indovest.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total data dalam DataFrame awal: 68207\n",
      "---\n",
      "Training Set: 54565 (80.00%)\n",
      "Validation Set: 6820 (10.00%)\n",
      "Test Set: 6822 (10.00%)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "def split_dataframe_temporal_by_ratio(df, temporal_column, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n",
    "    if not (0 <= train_ratio <= 1 and 0 <= val_ratio <= 1 and 0 <= test_ratio <= 1):\n",
    "        raise ValueError(\"Rasio (train_ratio, val_ratio, test_ratio) harus antara 0 dan 1.\")\n",
    "    if (train_ratio + val_ratio + test_ratio) > 1.001:\n",
    "        print(\"Peringatan: Jumlah rasio melebihi 1.0. Set test akan disesuaikan untuk memastikan total 100%.\")\n",
    "\n",
    "    df_sorted = df.sort_values(by=temporal_column).reset_index(drop=True)\n",
    "\n",
    "    total_size = len(df_sorted)\n",
    "    \n",
    "    train_size = int(total_size * train_ratio)\n",
    "    val_size = int(total_size * val_ratio)\n",
    "    \n",
    "    test_size = total_size - train_size - val_size \n",
    "\n",
    "    train_df = df_sorted.iloc[:train_size]\n",
    "    val_df = df_sorted.iloc[train_size : train_size + val_size]\n",
    "    test_df = df_sorted.iloc[train_size + val_size : train_size + val_size + test_size]\n",
    "\n",
    "    return train_df, val_df, test_df\n",
    "\n",
    "df = pd.read_csv(r'norm_IndovestDKG_encoded_indovest.csv')\n",
    "\n",
    "TRAIN_RATIO = 0.80\n",
    "VALID_RATIO = 0.10\n",
    "TEST_RATIO = 0.10 \n",
    "\n",
    "train_df, val_df, test_df = split_dataframe_temporal_by_ratio(\n",
    "    df,\n",
    "    temporal_column='temporal_id',\n",
    "    train_ratio=TRAIN_RATIO,\n",
    "    val_ratio=VALID_RATIO,\n",
    "    test_ratio=TEST_RATIO\n",
    ")\n",
    "\n",
    "print(f\"Total data dalam DataFrame awal: {len(df)}\")\n",
    "print(\"---\")\n",
    "print(f\"Training Set: {len(train_df)} ({len(train_df)/len(df)*100:.2f}%)\")\n",
    "print(f\"Validation Set: {len(val_df)} ({len(val_df)/len(df)*100:.2f}%)\")\n",
    "print(f\"Test Set: {len(test_df)} ({len(test_df)/len(df)*100:.2f}%)\")\n",
    "print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(r'splited/train.csv', index=False)\n",
    "val_df.to_csv(r'splited/valid.csv', index=False)\n",
    "test_df.to_csv(r'splited/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# formating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def convert_data_to_txt_format():\n",
    "    current_dir = Path('.')\n",
    "    \n",
    "    base_dir = current_dir.parent / 'result'\n",
    "    splited_dir = base_dir / 'splited'\n",
    "    output_dir = splited_dir / 'final_txt_format'\n",
    "    \n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    conversions = [\n",
    "        (splited_dir / 'train.csv', output_dir / 'train.txt', 'space_separated'),\n",
    "        (splited_dir / 'valid.csv', output_dir / 'valid.txt', 'space_separated'),\n",
    "        (splited_dir / 'test.csv', output_dir / 'test.txt', 'space_separated'),\n",
    "        (base_dir / 'norm_IndovestDKG_encoded_entity_id.csv', output_dir / 'entity2id.txt', 'entity_mapping'),\n",
    "        (base_dir / 'norm_IndovestDKG_relation_id.csv', output_dir / 'relation2id.txt', 'relation_mapping')\n",
    "    ]\n",
    "    \n",
    "    for input_file, output_file, conversion_type in conversions:\n",
    "        if not input_file.exists():\n",
    "            continue\n",
    "            \n",
    "        if conversion_type == 'space_separated':\n",
    "            df = pd.read_csv(input_file)\n",
    "            df.to_csv(output_file, sep=' ', index=False, header=False)\n",
    "            \n",
    "        elif conversion_type == 'entity_mapping':\n",
    "            df = pd.read_csv(input_file)\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                for _, row in df.iterrows():\n",
    "                    f.write(f\"{row['entity_name']}\\t{row['entity_id']}\\n\")\n",
    "                    \n",
    "        elif conversion_type == 'relation_mapping':\n",
    "            df = pd.read_csv(input_file)\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                for _, row in df.iterrows():\n",
    "                    f.write(f\"{row['relation']}\\t{row['relation_id']}\\n\")\n",
    "\n",
    "def auto_detect_and_convert():\n",
    "    current_dir = Path('.')\n",
    "    \n",
    "    possible_bases = [\n",
    "        current_dir,\n",
    "        current_dir.parent,\n",
    "        current_dir / 'experiments' / 'result',\n",
    "        current_dir.parent / 'result'\n",
    "    ]\n",
    "    \n",
    "    base_dir = None\n",
    "    for possible_base in possible_bases:\n",
    "        if (possible_base / 'splited' / 'train.csv').exists():\n",
    "            base_dir = possible_base\n",
    "            break\n",
    "    \n",
    "    if base_dir is None:\n",
    "        return\n",
    "    \n",
    "    splited_dir = base_dir / 'splited'\n",
    "    output_dir = splited_dir / 'final_txt_format'\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    conversions = [\n",
    "        (splited_dir / 'train.csv', output_dir / 'train.txt', 'space_separated'),\n",
    "        (splited_dir / 'valid.csv', output_dir / 'valid.txt', 'space_separated'),\n",
    "        (splited_dir / 'test.csv', output_dir / 'test.txt', 'space_separated'),\n",
    "        (base_dir / 'norm_IndovestDKG_encoded_entity_id.csv', output_dir / 'entity2id.txt', 'entity_mapping'),\n",
    "        (base_dir / 'norm_IndovestDKG_relation_id.csv', output_dir / 'relation2id.txt', 'relation_mapping')\n",
    "    ]\n",
    "    \n",
    "    for input_file, output_file, conversion_type in conversions:\n",
    "        if not input_file.exists():\n",
    "            continue\n",
    "            \n",
    "        if conversion_type == 'space_separated':\n",
    "            df = pd.read_csv(input_file)\n",
    "            df.to_csv(output_file, sep=' ', index=False, header=False)\n",
    "        elif conversion_type == 'entity_mapping':\n",
    "            df = pd.read_csv(input_file)\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                for _, row in df.iterrows():\n",
    "                    f.write(f\"{row['entity_name']}\\t{row['entity_id']}\\n\")\n",
    "        elif conversion_type == 'relation_mapping':\n",
    "            df = pd.read_csv(input_file)\n",
    "            with open(output_file, 'w', encoding='utf-8') as f:\n",
    "                for _, row in df.iterrows():\n",
    "                    f.write(f\"{row['relation']}\\t{row['relation_id']}\\n\")\n",
    "\n",
    "def quick_convert():\n",
    "    base = Path('./experiments/result')\n",
    "    out = base / 'splited/final_txt_format'\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for split in ['train', 'valid', 'test']:\n",
    "        pd.read_csv(base / f'splited/{split}.csv').to_csv(\n",
    "            out / f'{split}.txt', sep=' ', index=False, header=False\n",
    "        )\n",
    "    \n",
    "    pd.read_csv(base / 'norm_IndovestDKG_encoded_entity_id.csv').apply(\n",
    "        lambda row: f\"{row['entity_name']}\\t{row['entity_id']}\", axis=1\n",
    "    ).to_csv(out / 'entity2id.txt', index=False, header=False, quoting=3)\n",
    "    \n",
    "    pd.read_csv(base / 'norm_IndovestDKG_relation_id.csv').apply(\n",
    "        lambda row: f\"{row['relation']}\\t{row['relation_id']}\", axis=1\n",
    "    ).to_csv(out / 'relation2id.txt', index=False, header=False, quoting=3)\n",
    "\n",
    "auto_detect_and_convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
